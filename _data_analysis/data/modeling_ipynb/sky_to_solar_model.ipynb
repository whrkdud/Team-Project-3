{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c1bc89d-fc8b-4085-8247-eb33fa162c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Sequential, save_model, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49fca932-8046-40d2-b01e-b6396be1b50c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15468\\197603555.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  power_10_df['Date and Time'] = pd.to_datetime(power_10_df['Date and Time'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15468\\197603555.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  power_11_df['Date and Time'] = pd.to_datetime(power_11_df['Date and Time'])\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15468\\197603555.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  power_12_df['Date and Time'] = pd.to_datetime(power_12_df['Date and Time'])\n"
     ]
    }
   ],
   "source": [
    "#1. 데이터 준비_전처리(data set processing)\n",
    "#1-1. 일별 초당 평균발전량 (date and time&AVG power)데이터 가공\n",
    "#1-1-1. csv파일 읽기\n",
    "power_10_df = pd.read_csv(\"./1Low-res_sky_images_kaggle/Power_measurements/2019_09_10.csv\")\n",
    "power_11_df = pd.read_csv(\"./1Low-res_sky_images_kaggle/Power_measurements/2019_09_11.csv\")\n",
    "power_12_df = pd.read_csv(\"./1Low-res_sky_images_kaggle/Power_measurements/2019_09_12.csv\")\n",
    "\n",
    "#1-1-2. 날짜&시간을 알려주는 컬럼['date and time']의 자료형태를 시간으로 바꾸기\n",
    "power_10_df['Date and Time'] = pd.to_datetime(power_10_df['Date and Time'])\n",
    "power_11_df['Date and Time'] = pd.to_datetime(power_11_df['Date and Time'])\n",
    "power_12_df['Date and Time'] = pd.to_datetime(power_12_df['Date and Time'])\n",
    "\n",
    "#1-1-3. power_10_df, power_11_df, power_12_df을 합치기\n",
    "power_df = pd.concat([power_10_df, power_11_df, power_12_df], axis = 0)\n",
    "\n",
    "#1-1-4.결측값 제거하기\n",
    "power_df.dropna(inplace=True)\n",
    "\n",
    "#1-1-5. 인덱스'Date and Time'에서 중복되는 경우에 대해서 groupby로 묶어서 평균값 주기 \n",
    "power_df_avg = power_df.groupby('Date and Time').mean()\n",
    "      \n",
    "#1-1-6. 인덱스'Date and Time'를 컬럼'DateTime'으로 만들기\n",
    "power_df_avg['DateTime'] = power_df_avg.index\n",
    "\n",
    "#1-1-7. 인덱스'Date and Time'를 reset하기\n",
    "power_df_avg = power_df_avg.reset_index(drop=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e314241-1d55-41ab-a7e7-d24cc62a925f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1-2.Image파일의 파일명 번호에 따른 Image의 촬영 시분초(사진번호, 시, 분, 초 )데이터의 가공\n",
    "#1-2-1. csv파일 읽기\n",
    "time_10_df = pd.read_csv(\"./1Low-res_sky_images_kaggle/Sky_images/10_09_2019/time.csv\")\n",
    "time_11_df = pd.read_csv(\"./1Low-res_sky_images_kaggle/Sky_images/11_09_2019/time.csv\")\n",
    "time_12_df = pd.read_csv(\"./1Low-res_sky_images_kaggle/Sky_images/11_09_2019/time.csv\")\n",
    "\n",
    "#1-2-2. csv 파일상에서는 사진번호1~3000까지의 데이터가 있지만, 실제 사진은 1~2999까지 있으므로 사진번호3000 제거하기\n",
    "time_10_df = time_10_df[:-1]\n",
    "time_11_df = time_11_df[:-1]\n",
    "time_12_df = time_12_df[:-1]\n",
    "\n",
    "#1-2-3. 날짜, 시간을 알려주는 컬럼['date and time']의 생성\n",
    "time_10_df['Date and Time'] = pd.to_datetime(time_10_df[['Hours', 'Minutes', 'Seconds']].assign(Day=10, Month=9, Year=2019))\n",
    "time_10_df = time_10_df.drop(['Hours', 'Minutes', 'Seconds'], axis=1)\n",
    "time_11_df['Date and Time'] = pd.to_datetime(time_11_df[['Hours', 'Minutes', 'Seconds']].assign(Day=11, Month=9, Year=2019))\n",
    "time_11_df = time_11_df.drop(['Hours', 'Minutes', 'Seconds'], axis=1)\n",
    "time_12_df['Date and Time'] = pd.to_datetime(time_12_df[['Hours', 'Minutes', 'Seconds']].assign(Day=12, Month=9, Year=2019))\n",
    "time_12_df = time_12_df.drop(['Hours', 'Minutes', 'Seconds'], axis=1)\n",
    "\n",
    "#1-2-4. 사진파일이 있는 폴더경로를 알려주는 컬럼['FilePath']의 생성\n",
    "folder = './1Low-res_sky_images_kaggle/Sky_images/10_09_2019/Images/'\n",
    "time_10_df['FilePath'] = [os.path.join(folder, str(image_number) + '.jpg').replace('\\\\', '/') for image_number in time_10_df['Image Number']]\n",
    "folder = './1Low-res_sky_images_kaggle/Sky_images/11_09_2019/Images/'\n",
    "time_11_df['FilePath'] = [os.path.join(folder, str(image_number) + '.jpg').replace('\\\\', '/') for image_number in time_11_df['Image Number']]\n",
    "folder = './1Low-res_sky_images_kaggle/Sky_images/12_09_2019/Images/'\n",
    "time_12_df['FilePath'] = [os.path.join(folder, str(image_number) + '.jpg').replace('\\\\', '/') for image_number in time_12_df['Image Number']]\n",
    "\n",
    "#1-2-5. 결측값 제거하기\n",
    "time_10_df.dropna(inplace=True)\n",
    "time_11_df.dropna(inplace=True)\n",
    "time_12_df.dropna(inplace=True)\n",
    "\n",
    "#1-2-6. 분단위로 데이터 정리를 위해 컬럼[Date and Time]에 floor을 분에 적용하여 분 이하에 값(초)가 없어진 컬럼[DateTime]을 생성\n",
    "time_10_df['DateTime'] = time_10_df['Date and Time'].dt.floor('min')\n",
    "time_11_df['DateTime'] = time_11_df['Date and Time'].dt.floor('min')\n",
    "time_12_df['DateTime'] = time_12_df['Date and Time'].dt.floor('min')\n",
    "\n",
    "#1-2-7. 분단위로 데이터 정리를 위해 컬럼[DateTime]을 groupby로 같은 분단위 시간끼리 묶기\n",
    "grouped_10 = time_10_df.groupby('DateTime')\n",
    "grouped_11 = time_11_df.groupby('DateTime')\n",
    "grouped_12 = time_12_df.groupby('DateTime')\n",
    "\n",
    "#1-2-8. 같은 분끼리 묶인 grouped_10의 컬럼'FilePath'에 ','를 기준으로 join하기\n",
    "aggregated_10 = grouped_10['FilePath'].agg(lambda x: ','.join(x))\n",
    "aggregated_11 = grouped_11['FilePath'].agg(lambda x: ','.join(x))\n",
    "aggregated_12 = grouped_12['FilePath'].agg(lambda x: ','.join(x))\n",
    "\n",
    "#1-2-9. reset_index로 인덱스를 다시 0~부터 리셋하고, 컬럼'FilePath'의 컬럼명을 'FilePaths'로 변경하기\n",
    "result_10 = aggregated_10.reset_index().rename(columns={'FilePath': 'FilePaths'})\n",
    "result_11 = aggregated_11.reset_index().rename(columns={'FilePath': 'FilePaths'})\n",
    "result_12 = aggregated_12.reset_index().rename(columns={'FilePath': 'FilePaths'})\n",
    "\n",
    "#1-2-10. 컬럼'FilePaths'의 파일경로들이 몇개인지 ','를 기준으로 len()으로 수를 세어 컬럼'NumberFiles'를 생성 후, 값을 주기\n",
    "result_10['NumberFiles'] = result_10['FilePaths'].str.split(',').str.len()\n",
    "result_11['NumberFiles'] = result_11['FilePaths'].str.split(',').str.len()\n",
    "result_12['NumberFiles'] = result_12['FilePaths'].str.split(',').str.len()\n",
    "\n",
    "#1-2-11. result_10,result_11,result_12(10,11,12일의 사진에 대한 정보)를 CONCAT으로 이어붙이기\n",
    "images_df = pd.concat([result_10, result_11, result_12], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5850446-a95e-4f6a-9468-e1534f7ed0c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1-3. 일별 초당 평균발전량 (date and time&AVG power)데이터와 Image파일의 파일명 번호에 따른 Image의 촬영 시분초(사진번호, 시, 분, 초 )데이터의 가공\n",
    "#1-3-1. power_df_avg와 images_df를 컬럼'DateTime'를 기준으로 MERGE하기\n",
    "merged_df = pd.merge(power_df_avg, images_df, on='DateTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e29bb75b-4a3e-45e3-a86c-683b8b72e965",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1-4.1000W/m^2단위로 category를 나누기\n",
    "#.1-4-1. 1000W/m^2단위별로 bins를 정하고, bins에 해당하는 labels를 정해주고, cut으로 해당 bins을 기준으로 labels를 해주는 컬럼'category'를 생성 후, 값 주기\n",
    "bins = [0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000]     #labels의 갯수는 bins의 갯수보다 1개가 적어야함.\n",
    "labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13']               #뒤에서 tensorflow.keras.utils.to_categorical을 쓰려면 labels는 int(숫자)여야함.  #한글 및 영어 혼용 불가\n",
    "merged_df['category'] = pd.cut(merged_df['AVG power'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a129fac5-5ee8-4ae3-92cb-80459af77b2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8997"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1-5. array형태의 독립변수(X) 준비\n",
    "#1-5-1. 파일 경로가 담긴 리스트형 자료 준비\n",
    "        #데이터프레임merged_df의 컬럼'FilePaths'를 뽑아 컬럼'NumberFiles'의 개수만큼 있는 파일경로들을 split(',')으로 분리하여 리스트file_list에 담기\n",
    "file_list= []\n",
    "for i in range(merged_df.shape[0]):\n",
    "    for j in range( merged_df['NumberFiles'][i]):\n",
    "        file=merged_df['FilePaths'][i].split(',')[j]\n",
    "        file_list.append(file)\n",
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eeeb720-1e14-42c7-9330-e6a88caced22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1-5-2. 빈 X를 만든 후, 리스트file_list상의 파일경로에 있는 이미지파일을 matplotlib.pyplot의 imread로 읽어들이고, cv2를 통해 이미지를 사이즈를 (150,150)으로 조절한 후 값을 X에 바꿔넣기\n",
    "X=np.zeros((8997,150,150,3))              #비어있는 어레이X만든 후, 교체해 넣기\n",
    "\n",
    "for idx,file in enumerate(file_list):\n",
    "    dt=plt.imread(file)\n",
    "    dt=cv.resize(dt,(150,150)).reshape(1,150,150,-1)\n",
    "    X[idx] = dt[:,:,:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8271b6b5-7693-429e-a3aa-dbfe566b7cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#1-6. list형태의 종속변수(y) 준비\n",
    "#1-6-1.컬럼'category'를 컬럼'NumberFiles'의 개수만큼 있는 반복하도록 값을 뽑아 리스트y에 담기\n",
    "y=[]\n",
    "for i in range(merged_df.shape[0]):\n",
    "    for j in range( merged_df['NumberFiles'][i]):\n",
    "        y_=merged_df['category'][i]\n",
    "        y.append(y_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c26f38-a20f-4297-bc95-8514c9d30b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#2. 머신러닝(딥러닝) 하기\n",
    "#2-1. train데이터, validation데이터, test데이터 세트 만들기\n",
    "#2-1-1. sklearn.model_selection.train_test_split을 통해 train데이터, validation데이터, test데이터 나누기\n",
    "X_, X_test, y_, y_test=train_test_split(X,y,test_size=.2)\n",
    "X_train, X_validation, y_train, y_validation=train_test_split(X_,y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16b68faf-77a6-4e14-9331-4438bc022c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#2-1-2.one-hot을 위해 tensorflow.keras.utils.to_categorical을 통해 y값들 바꾸기\n",
    "y_train = to_categorical(y_train)\n",
    "y_validation = to_categorical(y_validation)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd2e45df-af03-4bc9-8069-31b378bc3ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2-2. 네트워크 설계하기(CNN 모델)\n",
    "#2-2-1. VGG16모델(이미지 100가지를 분류한 모델(pretrained model)로, 이미 훈련이 되어 있어 이미지의 특징을 추출에 탁월함) (전이학습) \n",
    "conv_base=VGG16(include_top=False, input_shape=(150,150,3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebf41291-4a22-4acf-a1f7-19b5fd558019",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169/169 [==============================] - 130s 764ms/step\n",
      "57/57 [==============================] - 43s 751ms/step\n"
     ]
    }
   ],
   "source": [
    "#2-2-2. VGG16을 통해 얻은 이미지의 특징점 추출 및 저장\n",
    "X_train_trans=conv_base.predict(X_train)\n",
    "X_validation_trans=conv_base.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e853fce-517f-479c-945c-58f30c4ff72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#2-2-3. 나만의 모델 설계하기\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=X_train_trans.shape[1:]),  \n",
    "    Dense(1024, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(16, activation='relu'),\n",
    "    BatchNormalization(), \n",
    "    Dense(13, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9312305-336f-4ecd-b3b7-e0297390ba62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#2-3. compile하기\n",
    "optimizer = Adam()\n",
    "loss='categorical_crossentropy'\n",
    "metrics='accuracy'\n",
    "model.compile(optimizer=optimizer,loss=loss,metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f5e0d1-53b4-40db-990f-e62dfb3824d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "169/169 [==============================] - 20s 102ms/step - loss: 1.9452 - accuracy: 0.3600 - val_loss: 1.3007 - val_accuracy: 0.5661\n",
      "Epoch 2/200\n",
      "169/169 [==============================] - 18s 104ms/step - loss: 1.2838 - accuracy: 0.5557 - val_loss: 0.8965 - val_accuracy: 0.6217\n",
      "Epoch 3/200\n",
      "169/169 [==============================] - 16s 97ms/step - loss: 1.0481 - accuracy: 0.6218 - val_loss: 0.8111 - val_accuracy: 0.6933\n",
      "Epoch 4/200\n",
      "169/169 [==============================] - 16s 94ms/step - loss: 0.9170 - accuracy: 0.6626 - val_loss: 0.7293 - val_accuracy: 0.7217\n",
      "Epoch 5/200\n",
      "169/169 [==============================] - 16s 94ms/step - loss: 0.8503 - accuracy: 0.6872 - val_loss: 0.6417 - val_accuracy: 0.7522\n",
      "Epoch 6/200\n",
      "169/169 [==============================] - 16s 98ms/step - loss: 0.7739 - accuracy: 0.7197 - val_loss: 0.6143 - val_accuracy: 0.7794\n",
      "Epoch 7/200\n",
      "169/169 [==============================] - 17s 102ms/step - loss: 0.7187 - accuracy: 0.7393 - val_loss: 0.5563 - val_accuracy: 0.7939\n",
      "Epoch 8/200\n",
      "169/169 [==============================] - 17s 98ms/step - loss: 0.6799 - accuracy: 0.7576 - val_loss: 0.5607 - val_accuracy: 0.7850\n",
      "Epoch 9/200\n",
      "169/169 [==============================] - 16s 97ms/step - loss: 0.6504 - accuracy: 0.7669 - val_loss: 0.5281 - val_accuracy: 0.8011\n",
      "Epoch 10/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.6155 - accuracy: 0.7815 - val_loss: 0.4910 - val_accuracy: 0.8122\n",
      "Epoch 11/200\n",
      "169/169 [==============================] - 17s 98ms/step - loss: 0.5803 - accuracy: 0.7943 - val_loss: 0.4860 - val_accuracy: 0.8167\n",
      "Epoch 12/200\n",
      "169/169 [==============================] - 17s 99ms/step - loss: 0.5652 - accuracy: 0.8012 - val_loss: 0.5090 - val_accuracy: 0.8206\n",
      "Epoch 13/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.5556 - accuracy: 0.8075 - val_loss: 0.4812 - val_accuracy: 0.8356\n",
      "Epoch 14/200\n",
      "169/169 [==============================] - 16s 94ms/step - loss: 0.5275 - accuracy: 0.8082 - val_loss: 0.4538 - val_accuracy: 0.8217\n",
      "Epoch 15/200\n",
      "169/169 [==============================] - 16s 93ms/step - loss: 0.5161 - accuracy: 0.8110 - val_loss: 0.4622 - val_accuracy: 0.8256\n",
      "Epoch 16/200\n",
      "169/169 [==============================] - 16s 93ms/step - loss: 0.5107 - accuracy: 0.8238 - val_loss: 0.4283 - val_accuracy: 0.8350\n",
      "Epoch 17/200\n",
      "169/169 [==============================] - 16s 94ms/step - loss: 0.4828 - accuracy: 0.8284 - val_loss: 0.4197 - val_accuracy: 0.8372\n",
      "Epoch 18/200\n",
      "169/169 [==============================] - 16s 94ms/step - loss: 0.4840 - accuracy: 0.8229 - val_loss: 0.4873 - val_accuracy: 0.8239\n",
      "Epoch 19/200\n",
      "169/169 [==============================] - 16s 94ms/step - loss: 0.4677 - accuracy: 0.8358 - val_loss: 0.4672 - val_accuracy: 0.8289\n",
      "Epoch 20/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.4583 - accuracy: 0.8379 - val_loss: 0.4085 - val_accuracy: 0.8506\n",
      "Epoch 21/200\n",
      "169/169 [==============================] - 16s 93ms/step - loss: 0.4153 - accuracy: 0.8533 - val_loss: 0.3713 - val_accuracy: 0.8639\n",
      "Epoch 22/200\n",
      "169/169 [==============================] - 16s 94ms/step - loss: 0.4262 - accuracy: 0.8501 - val_loss: 0.3907 - val_accuracy: 0.8622\n",
      "Epoch 23/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.4047 - accuracy: 0.8531 - val_loss: 0.3935 - val_accuracy: 0.8600\n",
      "Epoch 24/200\n",
      "169/169 [==============================] - 16s 94ms/step - loss: 0.4162 - accuracy: 0.8545 - val_loss: 0.4194 - val_accuracy: 0.8567\n",
      "Epoch 25/200\n",
      "169/169 [==============================] - 16s 93ms/step - loss: 0.3909 - accuracy: 0.8588 - val_loss: 0.3656 - val_accuracy: 0.8628\n",
      "Epoch 26/200\n",
      "169/169 [==============================] - 16s 93ms/step - loss: 0.3853 - accuracy: 0.8629 - val_loss: 0.4416 - val_accuracy: 0.8461\n",
      "Epoch 27/200\n",
      "169/169 [==============================] - 16s 93ms/step - loss: 0.3682 - accuracy: 0.8729 - val_loss: 0.3819 - val_accuracy: 0.8567\n",
      "Epoch 28/200\n",
      "169/169 [==============================] - 16s 93ms/step - loss: 0.3543 - accuracy: 0.8744 - val_loss: 0.3574 - val_accuracy: 0.8644\n",
      "Epoch 29/200\n",
      "169/169 [==============================] - 17s 99ms/step - loss: 0.3855 - accuracy: 0.8621 - val_loss: 0.4052 - val_accuracy: 0.8522\n",
      "Epoch 30/200\n",
      "169/169 [==============================] - 16s 93ms/step - loss: 0.3471 - accuracy: 0.8779 - val_loss: 0.3618 - val_accuracy: 0.8683\n",
      "Epoch 31/200\n",
      "169/169 [==============================] - 16s 94ms/step - loss: 0.3573 - accuracy: 0.8742 - val_loss: 0.4322 - val_accuracy: 0.8561\n",
      "Epoch 32/200\n",
      "169/169 [==============================] - 16s 93ms/step - loss: 0.3318 - accuracy: 0.8851 - val_loss: 0.3411 - val_accuracy: 0.8717\n",
      "Epoch 33/200\n",
      "169/169 [==============================] - 16s 98ms/step - loss: 0.3233 - accuracy: 0.8866 - val_loss: 0.3639 - val_accuracy: 0.8611\n",
      "Epoch 34/200\n",
      "169/169 [==============================] - 17s 99ms/step - loss: 0.3234 - accuracy: 0.8831 - val_loss: 0.3628 - val_accuracy: 0.8606\n",
      "Epoch 35/200\n",
      "169/169 [==============================] - 17s 98ms/step - loss: 0.3291 - accuracy: 0.8823 - val_loss: 0.3363 - val_accuracy: 0.8722\n",
      "Epoch 36/200\n",
      "169/169 [==============================] - 17s 98ms/step - loss: 0.3033 - accuracy: 0.8968 - val_loss: 0.3639 - val_accuracy: 0.8678\n",
      "Epoch 37/200\n",
      "169/169 [==============================] - 16s 94ms/step - loss: 0.3066 - accuracy: 0.8886 - val_loss: 0.3572 - val_accuracy: 0.8722\n",
      "Epoch 38/200\n",
      "169/169 [==============================] - 16s 98ms/step - loss: 0.2951 - accuracy: 0.9003 - val_loss: 0.3119 - val_accuracy: 0.8867\n",
      "Epoch 39/200\n",
      "169/169 [==============================] - 16s 97ms/step - loss: 0.3187 - accuracy: 0.8896 - val_loss: 0.3599 - val_accuracy: 0.8600\n",
      "Epoch 40/200\n",
      "169/169 [==============================] - 17s 100ms/step - loss: 0.3003 - accuracy: 0.8907 - val_loss: 0.3259 - val_accuracy: 0.8822\n",
      "Epoch 41/200\n",
      "169/169 [==============================] - 17s 99ms/step - loss: 0.3160 - accuracy: 0.8914 - val_loss: 0.4083 - val_accuracy: 0.8617\n",
      "Epoch 42/200\n",
      "169/169 [==============================] - 16s 94ms/step - loss: 0.2992 - accuracy: 0.8948 - val_loss: 0.3288 - val_accuracy: 0.8772\n",
      "Epoch 43/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.2728 - accuracy: 0.9042 - val_loss: 0.3581 - val_accuracy: 0.8694\n",
      "Epoch 44/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.2752 - accuracy: 0.8981 - val_loss: 0.3334 - val_accuracy: 0.8811\n",
      "Epoch 45/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.2753 - accuracy: 0.8994 - val_loss: 0.3784 - val_accuracy: 0.8583\n",
      "Epoch 46/200\n",
      "169/169 [==============================] - 16s 97ms/step - loss: 0.2673 - accuracy: 0.9046 - val_loss: 0.3985 - val_accuracy: 0.8683\n",
      "Epoch 47/200\n",
      "169/169 [==============================] - 17s 99ms/step - loss: 0.2713 - accuracy: 0.9018 - val_loss: 0.3424 - val_accuracy: 0.8811\n",
      "Epoch 48/200\n",
      "169/169 [==============================] - 17s 99ms/step - loss: 0.2648 - accuracy: 0.9031 - val_loss: 0.3523 - val_accuracy: 0.8794\n",
      "Epoch 49/200\n",
      "169/169 [==============================] - 17s 98ms/step - loss: 0.2750 - accuracy: 0.9011 - val_loss: 0.3689 - val_accuracy: 0.8650\n",
      "Epoch 50/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.2480 - accuracy: 0.9062 - val_loss: 0.3146 - val_accuracy: 0.8894\n",
      "Epoch 51/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.2526 - accuracy: 0.9064 - val_loss: 0.2950 - val_accuracy: 0.8883\n",
      "Epoch 52/200\n",
      "169/169 [==============================] - 16s 97ms/step - loss: 0.2317 - accuracy: 0.9174 - val_loss: 0.3021 - val_accuracy: 0.8967\n",
      "Epoch 53/200\n",
      "169/169 [==============================] - 17s 98ms/step - loss: 0.2401 - accuracy: 0.9118 - val_loss: 0.3021 - val_accuracy: 0.8900\n",
      "Epoch 54/200\n",
      "169/169 [==============================] - 17s 99ms/step - loss: 0.2516 - accuracy: 0.9081 - val_loss: 0.3357 - val_accuracy: 0.8939\n",
      "Epoch 55/200\n",
      "169/169 [==============================] - 17s 98ms/step - loss: 0.2457 - accuracy: 0.9127 - val_loss: 0.3150 - val_accuracy: 0.8889\n",
      "Epoch 56/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.2378 - accuracy: 0.9159 - val_loss: 0.3398 - val_accuracy: 0.8861\n",
      "Epoch 57/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.2400 - accuracy: 0.9161 - val_loss: 0.3229 - val_accuracy: 0.8922\n",
      "Epoch 58/200\n",
      "169/169 [==============================] - 17s 98ms/step - loss: 0.2368 - accuracy: 0.9190 - val_loss: 0.2913 - val_accuracy: 0.9011\n",
      "Epoch 59/200\n",
      "169/169 [==============================] - 17s 99ms/step - loss: 0.2290 - accuracy: 0.9179 - val_loss: 0.3578 - val_accuracy: 0.8744\n",
      "Epoch 60/200\n",
      "169/169 [==============================] - 17s 101ms/step - loss: 0.2324 - accuracy: 0.9168 - val_loss: 0.3029 - val_accuracy: 0.8889\n",
      "Epoch 61/200\n",
      "169/169 [==============================] - 16s 94ms/step - loss: 0.2025 - accuracy: 0.9303 - val_loss: 0.3005 - val_accuracy: 0.8917\n",
      "Epoch 62/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.2202 - accuracy: 0.9181 - val_loss: 0.2914 - val_accuracy: 0.8978\n",
      "Epoch 63/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.2042 - accuracy: 0.9240 - val_loss: 0.3313 - val_accuracy: 0.8994\n",
      "Epoch 64/200\n",
      "169/169 [==============================] - 16s 97ms/step - loss: 0.2109 - accuracy: 0.9240 - val_loss: 0.2984 - val_accuracy: 0.8967\n",
      "Epoch 65/200\n",
      "169/169 [==============================] - 17s 99ms/step - loss: 0.2126 - accuracy: 0.9264 - val_loss: 0.3369 - val_accuracy: 0.8844\n",
      "Epoch 66/200\n",
      "169/169 [==============================] - 17s 99ms/step - loss: 0.2118 - accuracy: 0.9237 - val_loss: 0.2861 - val_accuracy: 0.9017\n",
      "Epoch 67/200\n",
      "169/169 [==============================] - 17s 99ms/step - loss: 0.2154 - accuracy: 0.9257 - val_loss: 0.2888 - val_accuracy: 0.9000\n",
      "Epoch 68/200\n",
      "169/169 [==============================] - 17s 102ms/step - loss: 0.1958 - accuracy: 0.9331 - val_loss: 0.3242 - val_accuracy: 0.8917\n",
      "Epoch 69/200\n",
      "169/169 [==============================] - 17s 101ms/step - loss: 0.1997 - accuracy: 0.9313 - val_loss: 0.2866 - val_accuracy: 0.9039\n",
      "Epoch 70/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.2026 - accuracy: 0.9294 - val_loss: 0.3177 - val_accuracy: 0.8967\n",
      "Epoch 71/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.2029 - accuracy: 0.9279 - val_loss: 0.3259 - val_accuracy: 0.8906\n",
      "Epoch 72/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.1859 - accuracy: 0.9342 - val_loss: 0.2932 - val_accuracy: 0.9039\n",
      "Epoch 73/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.1966 - accuracy: 0.9303 - val_loss: 0.3185 - val_accuracy: 0.8939\n",
      "Epoch 74/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.1914 - accuracy: 0.9322 - val_loss: 0.2962 - val_accuracy: 0.9050\n",
      "Epoch 75/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.1867 - accuracy: 0.9339 - val_loss: 0.2629 - val_accuracy: 0.9150\n",
      "Epoch 76/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.1781 - accuracy: 0.9350 - val_loss: 0.2862 - val_accuracy: 0.9033\n",
      "Epoch 77/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.1792 - accuracy: 0.9355 - val_loss: 0.3036 - val_accuracy: 0.9039\n",
      "Epoch 78/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.1771 - accuracy: 0.9359 - val_loss: 0.2875 - val_accuracy: 0.9039\n",
      "Epoch 79/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.1839 - accuracy: 0.9348 - val_loss: 0.3069 - val_accuracy: 0.8933\n",
      "Epoch 80/200\n",
      "169/169 [==============================] - 17s 98ms/step - loss: 0.1574 - accuracy: 0.9426 - val_loss: 0.3280 - val_accuracy: 0.8978\n",
      "Epoch 81/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.1822 - accuracy: 0.9385 - val_loss: 0.2800 - val_accuracy: 0.9083\n",
      "Epoch 82/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.1722 - accuracy: 0.9413 - val_loss: 0.2653 - val_accuracy: 0.9067\n",
      "Epoch 83/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.1584 - accuracy: 0.9416 - val_loss: 0.2911 - val_accuracy: 0.9022\n",
      "Epoch 84/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.1720 - accuracy: 0.9416 - val_loss: 0.3087 - val_accuracy: 0.8944\n",
      "Epoch 85/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.1640 - accuracy: 0.9455 - val_loss: 0.2777 - val_accuracy: 0.9083\n",
      "Epoch 86/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.1761 - accuracy: 0.9396 - val_loss: 0.3085 - val_accuracy: 0.9072\n",
      "Epoch 87/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.1715 - accuracy: 0.9353 - val_loss: 0.3370 - val_accuracy: 0.8900\n",
      "Epoch 88/200\n",
      "169/169 [==============================] - 16s 97ms/step - loss: 0.1768 - accuracy: 0.9370 - val_loss: 0.3120 - val_accuracy: 0.9033\n",
      "Epoch 89/200\n",
      "169/169 [==============================] - 16s 97ms/step - loss: 0.1628 - accuracy: 0.9414 - val_loss: 0.2907 - val_accuracy: 0.9122\n",
      "Epoch 90/200\n",
      "169/169 [==============================] - 16s 94ms/step - loss: 0.1557 - accuracy: 0.9452 - val_loss: 0.3062 - val_accuracy: 0.9006\n",
      "Epoch 91/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.1601 - accuracy: 0.9442 - val_loss: 0.3033 - val_accuracy: 0.9061\n",
      "Epoch 92/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.1591 - accuracy: 0.9427 - val_loss: 0.3081 - val_accuracy: 0.8994\n",
      "Epoch 93/200\n",
      "169/169 [==============================] - 17s 98ms/step - loss: 0.1610 - accuracy: 0.9431 - val_loss: 0.2848 - val_accuracy: 0.9072\n",
      "Epoch 94/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.1583 - accuracy: 0.9485 - val_loss: 0.2928 - val_accuracy: 0.9044\n",
      "Epoch 95/200\n",
      "169/169 [==============================] - 16s 97ms/step - loss: 0.1807 - accuracy: 0.9366 - val_loss: 0.2678 - val_accuracy: 0.9061\n",
      "Epoch 96/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.1561 - accuracy: 0.9448 - val_loss: 0.3035 - val_accuracy: 0.9000\n",
      "Epoch 97/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.1519 - accuracy: 0.9466 - val_loss: 0.3120 - val_accuracy: 0.8994\n",
      "Epoch 98/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.1486 - accuracy: 0.9503 - val_loss: 0.3113 - val_accuracy: 0.9044\n",
      "Epoch 99/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.1647 - accuracy: 0.9416 - val_loss: 0.2986 - val_accuracy: 0.8994\n",
      "Epoch 100/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.1450 - accuracy: 0.9481 - val_loss: 0.2924 - val_accuracy: 0.9039\n",
      "Epoch 101/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.1454 - accuracy: 0.9513 - val_loss: 0.3047 - val_accuracy: 0.9006\n",
      "Epoch 102/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.1546 - accuracy: 0.9466 - val_loss: 0.2699 - val_accuracy: 0.9061\n",
      "Epoch 103/200\n",
      "169/169 [==============================] - 16s 95ms/step - loss: 0.1446 - accuracy: 0.9503 - val_loss: 0.3062 - val_accuracy: 0.9094\n",
      "Epoch 104/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.1409 - accuracy: 0.9498 - val_loss: 0.3506 - val_accuracy: 0.8922\n",
      "Epoch 105/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.1328 - accuracy: 0.9542 - val_loss: 0.2983 - val_accuracy: 0.9017\n",
      "Epoch 106/200\n",
      "169/169 [==============================] - 16s 96ms/step - loss: 0.1410 - accuracy: 0.9548 - val_loss: 0.2832 - val_accuracy: 0.9150\n",
      "Epoch 107/200\n",
      "169/169 [==============================] - 17s 98ms/step - loss: 0.1412 - accuracy: 0.9540 - val_loss: 0.3046 - val_accuracy: 0.9072\n",
      "Epoch 108/200\n",
      "169/169 [==============================] - 17s 100ms/step - loss: 0.1372 - accuracy: 0.9511 - val_loss: 0.3533 - val_accuracy: 0.8950\n",
      "Epoch 109/200\n",
      "169/169 [==============================] - 17s 98ms/step - loss: 0.1417 - accuracy: 0.9511 - val_loss: 0.3332 - val_accuracy: 0.9072\n",
      "Epoch 110/200\n",
      "169/169 [==============================] - 17s 102ms/step - loss: 0.1469 - accuracy: 0.9481 - val_loss: 0.2815 - val_accuracy: 0.9111\n",
      "Epoch 111/200\n",
      "169/169 [==============================] - 16s 93ms/step - loss: 0.1435 - accuracy: 0.9515 - val_loss: 0.2819 - val_accuracy: 0.9167\n",
      "Epoch 112/200\n",
      "169/169 [==============================] - 16s 93ms/step - loss: 0.1321 - accuracy: 0.9540 - val_loss: 0.3321 - val_accuracy: 0.9072\n",
      "Epoch 113/200\n",
      "169/169 [==============================] - 16s 93ms/step - loss: 0.1365 - accuracy: 0.9513 - val_loss: 0.3002 - val_accuracy: 0.9139\n",
      "Epoch 114/200\n",
      " 20/169 [==>...........................] - ETA: 13s - loss: 0.1711 - accuracy: 0.9438"
     ]
    }
   ],
   "source": [
    "#2-4. fit하기(훈련하기)\n",
    "model.fit(X_train_trans,y_train,batch_size=32,validation_data=(X_validation_trans,y_validation),epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a329af5-7457-4165-a69e-3dec84de6f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#2-5. 평가하기\n",
    "model.evaluate(conv_base.predict(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48d77a-bdf4-462d-a298-57c8304cf432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#3.완성된 모델 저장하기\n",
    "save_model(model, 'C:\\\\Users\\\\user\\\\Desktop\\\\sprint_test_II\\\\_data_analysis\\\\code\\\\self_model\\\\model_sky.h5')\n",
    "save_model(conv_base,'C:\\\\Users\\\\user\\\\Desktop\\\\sprint_test_II\\\\_data_analysis\\\\code\\\\self_model\\\\VGG16_model_sky.h5')\n",
    "\n",
    "#4.저장한 모델 불러오기\n",
    "new_model = load_model('C:\\\\Users\\\\user\\\\Desktop\\\\sprint_test_II\\\\_data_analysis\\\\code\\\\self_model\\\\\\model_sky.h5')\n",
    "new_conv = load_model('C:\\\\Users\\\\user\\\\Desktop\\\\sprint_test_II\\\\_data_analysis\\\\code\\\\self_model\\\\VGG16_model_sky.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d9c9b2-76d2-417a-bf4b-79169f4bb776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#5. 완성한 모델을 임의의 테스트 이미지파일에 적용해보기\n",
    "#5-1. 임의의 테스트 이미지파일을 준비시키기 위한 함수\n",
    "def model_predict(x, conv_base):\n",
    "    x1 = cv.resize(x,(150,150))   #cv를 통해 이미지 사이즈 조정\n",
    "    x1 = x1[:,:,:3]               #테스트 이미지파일의 색에 대한 변수가 RGB가 아닌 RGBA일 경우를 대비하여 slicie함.\n",
    "    x1 = x1.reshape(1,150,150,3)  #모델 설계당시 input하기로 한 형태로 shape을 바꿔줌. \n",
    "    answer=np.argmax(new_model.predict(new_conv.predict(x1)))\n",
    "    return answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
